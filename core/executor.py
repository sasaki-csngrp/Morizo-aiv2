"""
TaskExecutor: Task execution specialist for the core layer.

This component manages task execution, dependency resolution, and parallel processing.
"""

import asyncio
import logging
from typing import List, Dict, Any, Set, Optional
from .models import Task, TaskStatus, TaskChainManager, ExecutionResult
from .exceptions import TaskExecutionError, CircularDependencyError, AmbiguityDetected
from .service_coordinator import ServiceCoordinator
from config.loggers import GenericLogger


class TaskExecutor:
    """Executes tasks with dependency resolution and parallel processing."""
    
    def __init__(self, service_coordinator: ServiceCoordinator, confirmation_service=None):
        self.service_coordinator = service_coordinator
        self.confirmation_service = confirmation_service
        self.logger = GenericLogger("core", "executor")
    
    async def execute(self, tasks: List[Task], user_id: str, task_chain_manager: TaskChainManager, token: str) -> ExecutionResult:
        """
        Execute a list of tasks with dependency resolution.
        
        Args:
            tasks: List of tasks to execute
            user_id: User identifier
            task_chain_manager: Task chain manager for progress tracking
            token: Authentication token
            
        Returns:
            ExecutionResult with status and outputs
        """
        try:
            self.logger.info(f"ğŸ”„ [EXECUTOR] ReActãƒ«ãƒ¼ãƒ—ã‚’é–‹å§‹ã—ã¾ã™: {len(tasks)}ä»¶ã®ã‚¿ã‚¹ã‚¯")
            self.logger.debug(f"ğŸ” [EXECUTOR] ãƒ¦ãƒ¼ã‚¶ãƒ¼ID: {user_id}")
            
            # ã€æ–°è¦è¿½åŠ ã€‘å®Ÿè¡Œå‰ã«æ›–æ˜§æ€§ãƒã‚§ãƒƒã‚¯
            if self.confirmation_service:
                self.logger.info(f"ğŸ” [EXECUTOR] å®Ÿè¡Œå‰ã«æ›–æ˜§æ€§ã‚’ãƒã‚§ãƒƒã‚¯ä¸­")
                
                # ConfirmationServiceã§æ›–æ˜§æ€§ãƒã‚§ãƒƒã‚¯
                ambiguity_result = await self.confirmation_service.detect_ambiguity(tasks, user_id, token)
                
                if ambiguity_result.requires_confirmation:
                    self.logger.info(f"âš ï¸ [EXECUTOR] æ›–æ˜§æ€§ãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸã€‚ç¢ºèªã‚’è¦æ±‚ã—ã¾ã™")
                    
                    # æœ€åˆã®æ›–æ˜§ãªã‚¿ã‚¹ã‚¯ã®æƒ…å ±ã‚’å–å¾—
                    first_ambiguous_task = ambiguity_result.ambiguous_tasks[0]
                    
                    return ExecutionResult(
                        status="needs_confirmation",
                        confirmation_context={
                            "ambiguity_info": first_ambiguous_task,
                            "user_response": "",
                            "original_tasks": tasks
                        },
                        outputs={},
                        message=first_ambiguous_task.details["message"]
                    )
                
                self.logger.info(f"âœ… [EXECUTOR] æ›–æ˜§æ€§ã¯æ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚å®Ÿè¡Œã‚’ç¶šè¡Œã—ã¾ã™")
            
            # Log task dependency graph
            self.logger.debug(f"ğŸ“Š [EXECUTOR] ã‚¿ã‚¹ã‚¯ä¾å­˜é–¢ä¿‚ã‚°ãƒ©ãƒ•:")
            for task in tasks:
                deps_str = f"deps: {task.dependencies}" if task.dependencies else "no dependencies"
                self.logger.debug(f"  - {task.id}: {task.service}.{task.method} ({deps_str})")
            
            remaining_tasks = tasks.copy()
            all_results = {}
            iteration = 0
            
            while remaining_tasks:
                iteration += 1
                self.logger.debug(f"ğŸ”„ [EXECUTOR] ReActåå¾© {iteration}: æ®‹ã‚Š{len(remaining_tasks)}ä»¶ã®ã‚¿ã‚¹ã‚¯")
                # Find executable group (tasks with resolved dependencies)
                executable_group = self._find_executable_group(remaining_tasks, all_results)
                
                if not executable_group:
                    # Check if we have remaining tasks but no executable ones
                    if remaining_tasks:
                        self.logger.error(f"âŒ [EXECUTOR] ã‚¿ã‚¹ã‚¯ã‚°ãƒ©ãƒ•ã§å¾ªç’°ä¾å­˜ãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸ")
                        raise CircularDependencyError("Circular dependency detected in task graph")
                    self.logger.info(f"âœ… [EXECUTOR] ã™ã¹ã¦ã®ã‚¿ã‚¹ã‚¯ãŒå®Œäº†ã—ã¾ã—ãŸ")
                    break
                
                # Log executable group
                group_task_ids = [task.id for task in executable_group]
                self.logger.debug(f"âš¡ [EXECUTOR] ã‚°ãƒ«ãƒ¼ãƒ— {iteration} ã‚’å®Ÿè¡Œä¸­: {group_task_ids}")
                for task in executable_group:
                    self.logger.debug(f"  - {task.id}: {task.service}.{task.method}")
                
                # Execute tasks in parallel
                group_results = await self._execute_group(executable_group, user_id, all_results, task_chain_manager, token)
                
                # Process results
                completed_count = 0
                failed_tasks = []
                for task, result in zip(executable_group, group_results):
                    if isinstance(result, AmbiguityDetected):
                        # Ambiguity detected - interrupt execution
                        self.logger.warning(f"âš ï¸ [EXECUTOR] ã‚¿ã‚¹ã‚¯ {task.id} ã§æ›–æ˜§æ€§ãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸ: {result.message}")
                        return ExecutionResult(
                            status="needs_confirmation",
                            confirmation_context=result.context,
                            message=result.message
                        )
                    
                    if isinstance(result, Exception):
                        self.logger.error(f"âŒ [EXECUTOR] ã‚¿ã‚¹ã‚¯ {task.id} ãŒå¤±æ•—ã—ã¾ã—ãŸ: {str(result)}")
                        task.status = TaskStatus.FAILED
                        task.error = str(result)
                        task_chain_manager.update_task_status(task.id, TaskStatus.FAILED, error=str(result))
                        failed_tasks.append(task)
                        
                        # USAGE_LIMIT_EXCEEDEDã‚¨ãƒ©ãƒ¼ã®å ´åˆã¯ã€å³åº§ã«ã‚¨ãƒ©ãƒ¼ã‚’è¿”ã™
                        if "USAGE_LIMIT_EXCEEDED" in str(result):
                            error_message = str(result).replace("USAGE_LIMIT_EXCEEDED: ", "")
                            # SSEã§ã‚¨ãƒ©ãƒ¼ã‚’é€ä¿¡
                            task_chain_manager.send_error(error_message)
                            return ExecutionResult(
                                status="error",
                                message=error_message
                            )
                    else:
                        self.logger.debug(f"âœ… [EXECUTOR] ã‚¿ã‚¹ã‚¯ {task.id} ãŒæ­£å¸¸ã«å®Œäº†ã—ã¾ã—ãŸ")
                        task.status = TaskStatus.COMPLETED
                        task.result = result
                        all_results[task.id] = result
                        task_chain_manager.update_task_status(task.id, TaskStatus.COMPLETED, result)
                        completed_count += 1
                
                # å®Œäº†ã—ãŸã‚¿ã‚¹ã‚¯æ•°åˆ†ã ã‘é€²æ—ã‚’æ›´æ–°
                if completed_count > 0:
                    task_chain_manager.current_step += completed_count
                    
                    # å®Œäº†ã—ãŸã‚¿ã‚¹ã‚¯ã®æƒ…å ±ã‚’ä½¿ç”¨
                    completed_tasks = [task for task, result in zip(executable_group, group_results) 
                                     if not isinstance(result, Exception) and not isinstance(result, AmbiguityDetected)]
                    
                    if completed_tasks:
                        # æœ€åˆã®å®Œäº†ã‚¿ã‚¹ã‚¯ã®æƒ…å ±ã‚’ä½¿ç”¨
                        first_completed_task = completed_tasks[0]
                        task_chain_manager.send_progress(first_completed_task.id, "å®Œäº†", f"{completed_count}å€‹ã®ã‚¿ã‚¹ã‚¯ãŒå®Œäº†ã—ã¾ã—ãŸ")
                
                # Remove completed and failed tasks from remaining
                # å¤±æ•—ã—ãŸã‚¿ã‚¹ã‚¯ã‚‚remaining_tasksã‹ã‚‰å‰Šé™¤ã™ã‚‹ï¼ˆCircular dependencyã‚¨ãƒ©ãƒ¼ã‚’é˜²ããŸã‚ï¼‰
                processed_ids = [task.id for task in executable_group]
                remaining_tasks = [t for t in remaining_tasks if t.id not in processed_ids]
                self.logger.debug(f"ğŸ“Š [EXECUTOR] ã‚¿ã‚¹ã‚¯ã‚’å‡¦ç†ã—ã¾ã—ãŸ: {len(processed_ids)}ä»¶ ({completed_count}ä»¶å®Œäº†, {len(failed_tasks)}ä»¶å¤±æ•—), æ®‹ã‚Š{len(remaining_tasks)}ä»¶")
            
            self.logger.info("âœ… [EXECUTOR] ReActãƒ«ãƒ¼ãƒ—ãŒæ­£å¸¸ã«å®Œäº†ã—ã¾ã—ãŸ")
            return ExecutionResult(status="success", outputs=all_results)
            
        except AmbiguityDetected as e:
            return ExecutionResult(
                status="needs_confirmation",
                confirmation_context=e.context,
                message=e.message
            )
        except Exception as e:
            self.logger.error(f"ã‚¿ã‚¹ã‚¯å®Ÿè¡Œã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}")
            return ExecutionResult(status="error", message=str(e))
    
    def _find_executable_group(self, tasks: List[Task], completed_results: Dict[str, Any]) -> List[Task]:
        """Find tasks that can be executed (dependencies resolved)."""
        executable = []
        
        for task in tasks:
            if task.status != TaskStatus.PENDING:
                continue
                
            # Check if all dependencies are completed
            if self._are_dependencies_satisfied(task, completed_results):
                executable.append(task)
        
        return executable
    
    def _are_dependencies_satisfied(self, task: Task, completed_results: Dict[str, Any]) -> bool:
        """Check if all task dependencies are satisfied."""
        for dep_id in task.dependencies:
            if dep_id not in completed_results:
                return False
        return True
    
    async def _execute_group(self, tasks: List[Task], user_id: str, previous_results: Dict[str, Any], task_chain_manager: TaskChainManager, token: str) -> List[Any]:
        """Execute a group of tasks in parallel."""
        coroutines = []
        
        for task in tasks:
            task.status = TaskStatus.RUNNING
            task_chain_manager.update_task_status(task.id, TaskStatus.RUNNING)
            
            coroutine = self._execute_single_task(task, user_id, previous_results, token, task_chain_manager)
            coroutines.append(coroutine)
        
        # Execute all tasks in parallel
        results = await asyncio.gather(*coroutines, return_exceptions=True)
        return results
    
    async def _execute_single_task(self, task: Task, user_id: str, previous_results: Dict[str, Any], token: str, task_chain_manager: TaskChainManager = None) -> Any:
        """Execute a single task with data injection."""
        try:
            self.logger.info(f"ğŸš€ [EXECUTOR] ã‚¿ã‚¹ã‚¯ {task.id} ã‚’é–‹å§‹ã—ã¾ã™: {task.service}.{task.method}")
            
            # åˆ©ç”¨å›æ•°åˆ¶é™ãƒã‚§ãƒƒã‚¯ï¼ˆçŒ®ç«‹ææ¡ˆæ©Ÿèƒ½ï¼‰
            if task.service == "recipe_service" and task.method == "generate_menu_plan":
                # çŒ®ç«‹ä¸€æ‹¬ææ¡ˆã®åˆ¶é™ãƒã‚§ãƒƒã‚¯
                from api.utils.subscription_service import SubscriptionService
                from mcp_servers.utils import get_authenticated_client
                
                subscription_service = SubscriptionService()
                client = get_authenticated_client(user_id, token)
                
                is_allowed, limit_info = await subscription_service.check_usage_limit(user_id, "menu_bulk", client)
                if not is_allowed:
                    self.logger.warning(f"âš ï¸ [EXECUTOR] Menu bulk usage limit exceeded for user: {user_id}")
                    error_msg = limit_info.get("error", "åˆ©ç”¨å›æ•°åˆ¶é™ã«é”ã—ã¾ã—ãŸ")
                    raise Exception(f"USAGE_LIMIT_EXCEEDED: {error_msg}")
                
                # åˆ¶é™ãƒã‚§ãƒƒã‚¯é€šéå¾Œã€å®Ÿè¡Œå‰ã«åˆ©ç”¨å›æ•°ã‚’ã‚¤ãƒ³ã‚¯ãƒªãƒ¡ãƒ³ãƒˆ
                increment_result = await subscription_service.increment_usage(user_id, "menu_bulk", client)
                if not increment_result.get("success"):
                    self.logger.warning(f"âš ï¸ [EXECUTOR] menu_bulk åˆ©ç”¨å›æ•°ã®ã‚¤ãƒ³ã‚¯ãƒªãƒ¡ãƒ³ãƒˆã«å¤±æ•—ã—ã¾ã—ãŸ: {increment_result.get('error')}")
            
            elif task.service == "recipe_service" and task.method == "generate_proposals":
                # æ®µéšçš„ææ¡ˆã®åˆ¶é™ãƒã‚§ãƒƒã‚¯
                from api.utils.subscription_service import SubscriptionService
                from mcp_servers.utils import get_authenticated_client
                
                subscription_service = SubscriptionService()
                client = get_authenticated_client(user_id, token)
                
                is_allowed, limit_info = await subscription_service.check_usage_limit(user_id, "menu_step", client)
                if not is_allowed:
                    self.logger.warning(f"âš ï¸ [EXECUTOR] Menu step usage limit exceeded for user: {user_id}")
                    error_msg = limit_info.get("error", "åˆ©ç”¨å›æ•°åˆ¶é™ã«é”ã—ã¾ã—ãŸ")
                    raise Exception(f"USAGE_LIMIT_EXCEEDED: {error_msg}")
                
                # åˆ¶é™ãƒã‚§ãƒƒã‚¯é€šéå¾Œã€å®Ÿè¡Œå‰ã«åˆ©ç”¨å›æ•°ã‚’ã‚¤ãƒ³ã‚¯ãƒªãƒ¡ãƒ³ãƒˆ
                increment_result = await subscription_service.increment_usage(user_id, "menu_step", client)
                if not increment_result.get("success"):
                    self.logger.warning(f"âš ï¸ [EXECUTOR] menu_step åˆ©ç”¨å›æ•°ã®ã‚¤ãƒ³ã‚¯ãƒªãƒ¡ãƒ³ãƒˆã«å¤±æ•—ã—ã¾ã—ãŸ: {increment_result.get('error')}")
            
            # Inject data from previous tasks
            injected_params = self._inject_data(task.parameters, previous_results)
            
            # Phase 1F: session_get_proposed_titlesã®sse_session_idã‚’å®Ÿéš›ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³IDã§ç½®ãæ›ãˆ
            if task.method == "session_get_proposed_titles" and task_chain_manager and task_chain_manager.sse_session_id:
                # ãƒ—ãƒ©ãƒ³ãƒŠãƒ¼ãŒç”Ÿæˆã—ãŸå›ºå®šå€¤ï¼ˆä¾‹: "session123"ï¼‰ã‚’å®Ÿéš›ã®sse_session_idã§ç½®ãæ›ãˆ
                if "sse_session_id" in injected_params:
                    old_value = injected_params["sse_session_id"]
                    injected_params["sse_session_id"] = task_chain_manager.sse_session_id
                    self.logger.info(f"ğŸ”„ [EXECUTOR] Replaced sse_session_id: '{old_value}' â†’ '{task_chain_manager.sse_session_id}'")
            
            self.logger.debug(f"ğŸ“¥ [EXECUTOR] Task {task.id} input parameters: {injected_params}")
            
            # Execute service method with token
            # Phase 3A: sse_session_idã‚’parametersã«è¿½åŠ ï¼ˆgenerate_proposalsã®ã¿ï¼‰
            if task_chain_manager and task_chain_manager.sse_session_id and task.method == "generate_proposals":
                injected_params["sse_session_id"] = task_chain_manager.sse_session_id
            
            # RAGæ¤œç´¢çµæœã®URLã‚’åˆ©ç”¨ã—ã¦Webæ¤œç´¢ã‚’ã‚¹ã‚­ãƒƒãƒ—ã™ã‚‹å‡¦ç†
            # search_recipes_from_webã®å ´åˆã€task3ã®çµæœã‹ã‚‰rag_resultsã‚’æ§‹ç¯‰
            if task.method == "search_recipes_from_web" and "task3" in previous_results:
                task3_result = previous_results["task3"]
                if isinstance(task3_result, dict) and task3_result.get("success"):
                    task3_data = task3_result.get("result", {}).get("data", {})
                    
                    # æ®µéšçš„ææ¡ˆã®å ´åˆ: candidatesã‹ã‚‰URLã‚’å–å¾—
                    candidates = task3_data.get("candidates", [])
                    rag_results = {}
                    
                    if candidates:
                        # æ®µéšçš„ææ¡ˆ: candidatesã‹ã‚‰URLã‚’å–å¾—
                        for candidate in candidates:
                            if candidate.get("source") == "rag" and candidate.get("url"):
                                title = candidate.get("title", "")
                                if title:
                                    rag_results[title] = {
                                        "url": candidate.get("url"),
                                        "category_detail": candidate.get("category_detail", ""),
                                        "category": candidate.get("category", "")
                                    }
                    else:
                        # çŒ®ç«‹ä¸€æ‹¬ææ¡ˆã®å ´åˆ: search_menu_from_ragã®çµæœã‹ã‚‰URLã‚’å–å¾—
                        # task3ã®çµæœã«_rag_urlsãŒå«ã¾ã‚Œã¦ã„ã‚‹å ´åˆã€ãã‚Œã‚’ä½¿ç”¨
                        rag_urls = task3_data.get("_rag_urls", {})
                        if rag_urls:
                            # _rag_urlsã‹ã‚‰rag_resultsã‚’æ§‹ç¯‰
                            for title, url_info in rag_urls.items():
                                if url_info.get("url"):
                                    rag_results[title] = {
                                        "url": url_info.get("url"),
                                        "category_detail": url_info.get("category_detail", ""),
                                        "category": url_info.get("category", "")
                                    }
                            self.logger.debug(f"ğŸ” [EXECUTOR] task3ã®çµæœã‹ã‚‰_rag_urlsã§{len(rag_results)}ä»¶ã®URLã‚’ç™ºè¦‹ã—ã¾ã—ãŸ")
                    
                    if rag_results:
                        injected_params["rag_results"] = rag_results
                        self.logger.debug(f"ğŸ” [EXECUTOR] URLä»˜ãRAGå€™è£œ{len(rag_results)}ä»¶ã®rag_resultsã‚’è¿½åŠ ã—ã¾ã—ãŸ")
            
            result = await self.service_coordinator.execute_service(
                task.service, task.method, injected_params, token
            )
            
            self.logger.debug(f"ğŸ“¤ [EXECUTOR] Task {task.id} output result: {result}")
            self.logger.debug(f"âœ… [EXECUTOR] ã‚¿ã‚¹ã‚¯ {task.id} ãŒæ­£å¸¸ã«å®Œäº†ã—ã¾ã—ãŸ")
            return result
            
        except Exception as e:
            self.logger.error(f"âŒ [EXECUTOR] ã‚¿ã‚¹ã‚¯ {task.id} ãŒå¤±æ•—ã—ã¾ã—ãŸ: {str(e)}")
            raise
    
    def _inject_data(self, parameters: Dict[str, Any], previous_results: Dict[str, Any]) -> Dict[str, Any]:
        """Inject data from previous task results into parameters (è¾æ›¸æ§‹é€ å¯¾å¿œç‰ˆ)."""
        injected = parameters.copy()
        
        
        for key, value in parameters.items():
            self.logger.debug(f"ğŸ” [EXECUTOR] Processing parameter: key={key}, value={value}, type={type(value)}")
            
            # Phase 1F: ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆå‚ç…§ã®å‡¦ç†ï¼ˆ"session.context.xxx"å½¢å¼ï¼‰
            if isinstance(value, str) and value.startswith("session.context."):
                self.logger.debug(f"ğŸ” [EXECUTOR] Detected session context reference: {value}")
                # ã“ã®æ™‚ç‚¹ã§ã¯æ–‡å­—åˆ—ã®ã¾ã¾ä¿æŒï¼ˆã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã§å®Ÿéš›ã«ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‹ã‚‰å–å¾—ã™ã‚‹ï¼‰
                # injected[key] = value  # æ—¢ã«valueãŒè¨­å®šã•ã‚Œã¦ã„ã‚‹ãŸã‚å¤‰æ›´ä¸è¦
                continue
            
            if isinstance(value, str):
                # çµåˆæ¼”ç®—: "task1.result.data + task2.result.data"
                if " + " in value and ".result." in value:
                    self.logger.debug(f"ğŸ” [EXECUTOR] Match: concatenation operation ({value})")
                    resolved_value = self._resolve_concatenation(value, previous_results)
                    if resolved_value is not None:
                        injected[key] = resolved_value
                        self.logger.debug(f"ğŸ”— [EXECUTOR] Resolved concatenation '{value}' = {len(resolved_value)} items")
                
                # è¾æ›¸ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰å‚ç…§: "task2.result.main_dish"
                elif ".result." in value and value.endswith((".main_dish", ".side_dish", ".soup")):
                    self.logger.debug(f"ğŸ” [EXECUTOR] Match: dict field reference ({value})")
                    field_value = self._extract_field_from_result(value, previous_results)
                    injected[key] = field_value
                    self.logger.debug(f"ğŸ”— [EXECUTOR] Extracted field '{value}' = '{field_value}'")
                
                # è¤‡æ•°ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰å‚ç…§: "task2.result.main_dish,task3.result.main_dish"
                elif "," in value and ".result." in value:
                    self.logger.debug(f"ğŸ” [EXECUTOR] Match: multiple fields reference ({value})")
                    field_values = self._extract_multiple_fields(value, previous_results)
                    injected[key] = field_values
                    self.logger.debug(f"ğŸ”— [EXECUTOR] Extracted multiple fields '{value}' = {field_values}")
                
                # ãƒã‚¹ãƒˆãƒ‘ã‚¹å‚ç…§: "task2.result.data", "task1.result.success" ãªã©
                elif ".result." in value:
                    self.logger.debug(f"ğŸ” [EXECUTOR] Match: nested path reference ({value})")
                    resolved_value = self._extract_nested_path(value, previous_results)
                    if resolved_value is not None:
                        injected[key] = resolved_value
                        self.logger.debug(f"ğŸ”— [EXECUTOR] Injected nested path '{value}' = {resolved_value}")
                
                # å˜ä¸€ã‚¿ã‚¹ã‚¯çµæœå‚ç…§: "task1.result"
                elif value.endswith(".result"):
                    self.logger.debug(f"ğŸ” [EXECUTOR] Match: single task result reference ({value})")
                    task_ref = value[:-7]  # "task1.result" -> "task1"
                    
                    if task_ref in previous_results:
                        # åœ¨åº«ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰é£Ÿæåãƒªã‚¹ãƒˆã‚’æŠ½å‡º
                        inventory_data = previous_results[task_ref]
                        
                        if isinstance(inventory_data, dict) and inventory_data.get("success"):
                            items = inventory_data.get("result", {}).get("data", [])
                            item_names = [item.get("item_name") for item in items if item.get("item_name")]
                            injected[key] = item_names
                            self.logger.debug(f"ğŸ”— [EXECUTOR] Injected {len(item_names)} items from {task_ref} to {key}")
                        else:
                            self.logger.warning(f"âš ï¸ [EXECUTOR] Inventory data is not successful: {inventory_data}")
                    else:
                        self.logger.warning(f"âš ï¸ [EXECUTOR] Task reference not found in previous_results: {task_ref}")
                else:
                    self.logger.debug(f"ğŸ” [EXECUTOR] No match: keeping original value ({value})")
                    # ãã®ä»–ã®æ–‡å­—åˆ—ã¯ãã®ã¾ã¾ä¿æŒ
                    pass
            
            elif isinstance(value, list):
                # ğŸ†• ãƒªã‚¹ãƒˆå‹ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®å‡¦ç†ã‚’è¿½åŠ 
                resolved_list = []
                
                for item in value:
                    if isinstance(item, str):
                        # ãƒªã‚¹ãƒˆå†…ã®å„è¦ç´ ã‚’è§£æ±º
                        if ".result." in item:
                            # ãƒã‚¹ãƒˆã•ã‚ŒãŸãƒ‘ã‚¹ï¼ˆtask2.result.data.main_dishãªã©ï¼‰ã®å ´åˆã¯_extract_nested_pathã‚’ä½¿ç”¨
                            # ã‚·ãƒ³ãƒ—ãƒ«ãªãƒ‘ã‚¹ï¼ˆtask2.result.main_dishï¼‰ã®å ´åˆã¯_extract_field_from_resultã‚’ä½¿ç”¨
                            dot_count = item.count(".")
                            if dot_count >= 3 and item.endswith((".main_dish", ".side_dish", ".soup")):
                                # ãƒã‚¹ãƒˆã•ã‚ŒãŸãƒ‘ã‚¹ã®å ´åˆ
                                field_value = self._extract_nested_path(item, previous_results)
                                resolved_list.append(field_value if field_value is not None else "")
                                self.logger.debug(f"ğŸ”— [EXECUTOR] Resolved nested path list item '{item}' = '{field_value}'")
                            elif item.endswith((".main_dish", ".side_dish", ".soup")):
                                # ã‚·ãƒ³ãƒ—ãƒ«ãªãƒ‘ã‚¹ã®å ´åˆ
                                field_value = self._extract_field_from_result(item, previous_results)
                                resolved_list.append(field_value)
                                self.logger.debug(f"ğŸ”— [EXECUTOR] Resolved list item '{item}' = '{field_value}'")
                            elif item.endswith(".result"):
                                # å˜ä¸€ã‚¿ã‚¹ã‚¯çµæœå‚ç…§
                                task_ref = item[:-7]
                                if task_ref in previous_results:
                                    task_result = previous_results[task_ref]
                                    if isinstance(task_result, dict) and task_result.get("success"):
                                        resolved_list.append(task_result.get("result", {}))
                                        self.logger.debug(f"ğŸ”— [EXECUTOR] Resolved list item '{item}' = task result")
                                else:
                                    resolved_list.append(item)
                            else:
                                # ãã®ä»–ã®.result.ã‚’å«ã‚€æ–‡å­—åˆ—ã¯ãƒã‚¹ãƒˆãƒ‘ã‚¹ã¨ã—ã¦å‡¦ç†
                                resolved_value = self._extract_nested_path(item, previous_results)
                                resolved_list.append(resolved_value if resolved_value is not None else item)
                                self.logger.debug(f"ğŸ”— [EXECUTOR] Resolved nested path list item '{item}' = '{resolved_value}'")
                        else:
                            # ãã®ä»–ã®æ–‡å­—åˆ—ã¯ãã®ã¾ã¾
                            resolved_list.append(item)
                    else:
                        # æ–‡å­—åˆ—ä»¥å¤–ã¯ãã®ã¾ã¾
                        resolved_list.append(item)
                
                injected[key] = resolved_list
                self.logger.debug(f"ğŸ”— [EXECUTOR] Resolved list parameter '{key}' = {resolved_list}")
            
            else:
                # ãã®ä»–ã®å‹ã¯ãã®ã¾ã¾ä¿æŒ
                pass
        
        return injected
    
    def _extract_field_from_result(self, value: str, previous_results: Dict[str, Any]) -> str:
        """è¾æ›¸æ§‹é€ ã‹ã‚‰ç‰¹å®šãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’æŠ½å‡º"""
        # "task2.result.main_dish" -> task2ã®main_dishãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’æŠ½å‡º
        parts = value.split(".")
        task_id = parts[0]
        field_name = parts[2]  # main_dish, side_dish, soup
        
        
        if task_id in previous_results:
            task_result = previous_results[task_id]
            
            if isinstance(task_result, dict) and task_result.get("success"):
                data = task_result.get("result", {}).get("data", {})
                field_value = data.get(field_name, "")
                self.logger.debug(f"ğŸ”— [EXECUTOR] Extracted '{field_name}' = '{field_value}'")
                return field_value
            else:
                self.logger.warning(f"âš ï¸ [EXECUTOR] Task result is not successful: {task_result}")
        else:
            self.logger.warning(f"âš ï¸ [EXECUTOR] Task '{task_id}' not found in previous_results")
        
        return ""
    
    def _extract_multiple_fields(self, value: str, previous_results: Dict[str, Any]) -> List[str]:
        """è¤‡æ•°ã®è¾æ›¸ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’æŠ½å‡ºã—ã¦ãƒªã‚¹ãƒˆåŒ–"""
        field_refs = [ref.strip() for ref in value.split(",")]
        results = []
        
        
        for field_ref in field_refs:
            if ".result." in field_ref:
                field_value = self._extract_field_from_result(field_ref, previous_results)
                if field_value:  # ç©ºæ–‡å­—åˆ—ã¯é™¤å¤–
                    results.append(field_value)
                    self.logger.debug(f"ğŸ”— [EXECUTOR] Added field value: '{field_value}'")
                else:
                    # ç©ºæ–‡å­—åˆ—ã®å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
                    pass
        
        self.logger.debug(f"ğŸ”— [EXECUTOR] Final extracted values: {results}")
        return results
    
    def _extract_nested_path(self, path: str, previous_results: Dict[str, Any]) -> Any:
        """ãƒã‚¹ãƒˆã•ã‚ŒãŸãƒ‘ã‚¹ã‚’è§£æ±ºï¼ˆä»»æ„ã®æ·±ã•ã«å¯¾å¿œ: task2.result.data.candidates ãªã©ï¼‰"""
        parts = path.split(".")
        if len(parts) < 2:
            self.logger.warning(f"âš ï¸ [EXECUTOR] Invalid nested path format: {path}")
            return None
        
        task_id = parts[0]  # "task2"
        path_after_task = parts[1:]  # ["result", "data", "candidates"]
        
        self.logger.debug(f"ğŸ” [EXECUTOR] Extracting nested path: {path}")
        self.logger.debug(f"ğŸ” [EXECUTOR] task_id={task_id}, nested_path={'.'.join(path_after_task)}")
        
        if task_id not in previous_results:
            self.logger.warning(f"âš ï¸ [EXECUTOR] Task '{task_id}' not found")
            return None
        
        task_result = previous_results[task_id]
        
        # å†å¸°çš„ã«ãƒ‘ã‚¹ã‚’è¾¿ã‚‹
        current_value = task_result
        
        for key in path_after_task:
            if isinstance(current_value, dict):
                if key in current_value:
                    current_value = current_value[key]
                    self.logger.debug(f"ğŸ”— [EXECUTOR] Traversing to '{key}': found {type(current_value).__name__}")
                else:
                    self.logger.warning(f"âš ï¸ [EXECUTOR] Key '{key}' not found in {list(current_value.keys())}")
                    return None
            else:
                self.logger.warning(f"âš ï¸ [EXECUTOR] Cannot traverse '{key}' from {type(current_value).__name__}")
                return None
        
        self.logger.debug(f"âœ… [EXECUTOR] Successfully extracted: {type(current_value).__name__}")
        
        # Phase 3A Fix: candidatesãŒè¾æ›¸ã®ãƒªã‚¹ãƒˆã®å ´åˆã€titleã®ãƒªã‚¹ãƒˆã«å¤‰æ›
        if isinstance(current_value, list) and len(current_value) > 0 and isinstance(current_value[0], dict):
            if "title" in current_value[0]:
                titles = [item["title"] for item in current_value if "title" in item]
                self.logger.debug(f"ğŸ”§ [EXECUTOR] Converted candidates list to title list: {len(titles)} titles")
                return titles
        
        return current_value
    
    def _resolve_concatenation(self, expression: str, previous_results: Dict[str, Any]) -> Optional[list]:
        """çµåˆæ¼”ç®—ã‚’è§£æ±ºï¼ˆä¾‹: "task1.result.data + task2.result.data"ï¼‰"""
        try:
            parts = expression.split(" + ")
            result_list = []
            
            for part in parts:
                part = part.strip()
                # ãƒã‚¹ãƒˆãƒ‘ã‚¹å‚ç…§ã¨ã—ã¦è§£æ±º
                resolved_value = self._extract_nested_path(part, previous_results)
                
                if resolved_value is not None:
                    # ãƒªã‚¹ãƒˆã®å ´åˆã¯æ‹¡å¼µã€ãã‚Œä»¥å¤–ã¯è¿½åŠ 
                    if isinstance(resolved_value, list):
                        result_list.extend(resolved_value)
                        self.logger.debug(f"ğŸ”— [EXECUTOR] Extended {len(resolved_value)} items from {part}")
                    else:
                        result_list.append(resolved_value)
                        self.logger.debug(f"ğŸ”— [EXECUTOR] Added item from {part}")
                else:
                    self.logger.warning(f"âš ï¸ [EXECUTOR] Could not resolve part: {part}")
            
            self.logger.debug(f"âœ… [EXECUTOR] Concatenation result: {len(result_list)} items")
            return result_list
            
        except Exception as e:
            self.logger.error(f"âŒ [EXECUTOR] _resolve_concatenation ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            return None
