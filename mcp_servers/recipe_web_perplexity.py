"""
Morizo AI v2 - Recipe Web Search Module (Perplexity)

This module provides web search functionality for recipe retrieval using Perplexity API.
"""

import os
import re
import asyncio
from typing import List, Dict, Any, Optional
from urllib.parse import urljoin
import requests
from dotenv import load_dotenv
from config.loggers import GenericLogger
from bs4 import BeautifulSoup
from mcp_servers.recipe_web_constants import RECIPE_SITES
from mcp_servers.recipe_web_utils import identify_site

# ç’°å¢ƒå¤‰æ•°ã®èª­ã¿è¾¼ã¿
load_dotenv()

# ãƒ­ã‚¬ãƒ¼ã®åˆæœŸåŒ–
logger = GenericLogger("mcp", "recipe_web_perplexity", initialize_logging=False)


class PerplexitySearchClient:
    """Perplexity APIã‚’ä½¿ç”¨ã—ãŸãƒ¬ã‚·ãƒ”æ¤œç´¢ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ"""
    
    def __init__(self):
        self.api_key = os.getenv('PERPLEXITY_API_KEY')
        
        if not self.api_key:
            raise ValueError("PERPLEXITY_API_KEY is required")
        
        self.api_url = "https://api.perplexity.ai/chat/completions"
    
    async def search_recipes(self, recipe_title: str, num_results: int = 5) -> List[Dict[str, Any]]:
        """ãƒ¬ã‚·ãƒ”æ¤œç´¢ã‚’å®Ÿè¡Œï¼ˆPerplexity APIä½¿ç”¨ï¼‰"""
        logger.debug(f"ğŸ” [PERPLEXITY] Searching recipes")
        logger.debug(f"ğŸ” [PERPLEXITY] Recipe title: {recipe_title}")
        
        try:
            # æ¤œç´¢ã‚¯ã‚¨ãƒªã‚’æ§‹ç¯‰
            query = self._build_recipe_query(recipe_title)
            
            # Perplexity APIã‚’å‘¼ã³å‡ºã—
            headers = {
                "Authorization": f"Bearer {self.api_key}",
                "Content-Type": "application/json"
            }
            
            payload = {
                "model": "sonar",
                "messages": [
                    {
                        "role": "system",
                        "content": "ã‚ãªãŸã¯ãƒ¬ã‚·ãƒ”æ¤œç´¢ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚ãƒ¬ã‚·ãƒ”ã®URLã‚’æä¾›ã—ã¦ãã ã•ã„ã€‚"
                    },
                    {
                        "role": "user",
                        "content": query
                    }
                ],
                "max_tokens": 1000,
                "temperature": 0.2
            }
            
            response = requests.post(
                self.api_url,
                headers=headers,
                json=payload,
                timeout=30
            )
            
            # ã‚¨ãƒ©ãƒ¼ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®è©³ç´°ã‚’å–å¾—
            if response.status_code != 200:
                error_detail = response.text
                logger.error(f"âŒ [PERPLEXITY] API Error {response.status_code}: {error_detail}")
                logger.error(f"âŒ [PERPLEXITY] Request payload: {payload}")
                response.raise_for_status()
            
            result = response.json()
            
            # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‹ã‚‰URLã‚’æŠ½å‡ºï¼ˆéåŒæœŸã§ç”»åƒã‚‚å–å¾—ï¼‰
            recipes = await self._parse_perplexity_response(result, recipe_title, num_results)
            
            logger.debug(f"âœ… [PERPLEXITY] Found recipes")
            logger.debug(f"ğŸ“Š [PERPLEXITY] Found {len(recipes)} recipes")
            return recipes
            
        except Exception as e:
            logger.error(f"âŒ [PERPLEXITY] Search error: {e}")
            return []
    
    def _build_recipe_query(self, recipe_title: str) -> str:
        """ãƒ¬ã‚·ãƒ”æ¤œç´¢ç”¨ã®ã‚¯ã‚¨ãƒªã‚’æ§‹ç¯‰"""
        # è¤‡æ•°ã‚µã‚¤ãƒˆã‚’å¯¾è±¡ã¨ã—ãŸæ¤œç´¢ã‚¯ã‚¨ãƒª
        sites = "ã¾ãŸã¯".join(RECIPE_SITES.keys())
        return f"{recipe_title} ãƒ¬ã‚·ãƒ” {sites} ã®URLã‚’æ•™ãˆã¦ãã ã•ã„ã€‚URLã®ã¿ã‚’è¿”ã—ã¦ãã ã•ã„ã€‚"
    
    async def _parse_perplexity_response(self, response: Dict, recipe_title: str, num_results: int) -> List[Dict[str, Any]]:
        """Perplexity APIã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’è§£æãƒ»æ•´å½¢ï¼ˆç”»åƒURLã‚‚å–å¾—ï¼‰"""
        recipes = []
        
        try:
            # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‹ã‚‰ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å–å¾—
            choices = response.get('choices', [])
            if not choices:
                logger.warning(f"âš ï¸ [PERPLEXITY] No choices in response")
                return recipes
            
            content = choices[0].get('message', {}).get('content', '')
            
            # URLã‚’æŠ½å‡ºï¼ˆæ­£è¦è¡¨ç¾ã§URLã‚’æ¤œç´¢ï¼‰
            url_pattern = r'https?://[^\s<>"{}|\\^`\[\]]+'
            urls = re.findall(url_pattern, content)
            
            # ãƒ¬ã‚·ãƒ”ã‚µã‚¤ãƒˆã®URLã®ã¿ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
            recipe_urls = []
            for url in urls:
                for site in RECIPE_SITES.keys():
                    if site in url:
                        recipe_urls.append(url)
                        break
            
            # é‡è¤‡ã‚’é™¤å»
            recipe_urls = list(dict.fromkeys(recipe_urls))
            
            # è¦æ±‚ã•ã‚ŒãŸæ•°ã ã‘å‡¦ç†ï¼ˆç”»åƒURLã‚‚ä¸¦åˆ—å–å¾—ï¼‰
            recipe_data_list = []
            image_tasks = []
            
            for url in recipe_urls[:num_results]:
                site_name = identify_site(url)
                recipe_data_list.append({
                    'url': url,
                    'site_name': site_name
                })
                # ç”»åƒå–å¾—ã‚¿ã‚¹ã‚¯ã‚’ä½œæˆ
                image_tasks.append(self._fetch_recipe_image(url))
            
            # ç”»åƒå–å¾—ã‚’ä¸¦åˆ—å®Ÿè¡Œ
            image_urls = await asyncio.gather(*image_tasks)
            
            # ãƒ¬ã‚·ãƒ”ãƒ‡ãƒ¼ã‚¿ã¨ç”»åƒURLã‚’çµåˆ
            from config.constants import DEFAULT_RECIPE_IMAGE_URL
            for recipe_data, image_url in zip(recipe_data_list, image_urls):
                recipe = {
                    'title': recipe_title,
                    'url': recipe_data['url'],
                    'description': f'{recipe_title}ã®ãƒ¬ã‚·ãƒ”ï¼ˆPerplexityæ¤œç´¢ï¼‰',
                    'site': recipe_data['site_name'],
                    'source': RECIPE_SITES.get(recipe_data['site_name'], 'Unknown'),
                    'image_url': image_url if image_url else DEFAULT_RECIPE_IMAGE_URL
                }
                recipes.append(recipe)
            
        except Exception as e:
            logger.error(f"âŒ [PERPLEXITY] Error parsing response: {e}")
        
        return recipes
    
    def _normalize_image_url(self, image_url: str, base_url: str) -> str:
        """ç”»åƒURLã‚’æ­£è¦åŒ–ï¼ˆç›¸å¯¾URLã‚’çµ¶å¯¾URLã«å¤‰æ›ï¼‰"""
        if image_url.startswith('//'):
            return 'https:' + image_url
        elif image_url.startswith('/'):
            return urljoin(base_url, image_url)
        return image_url
    
    def _fetch_ogp_image(self, soup: BeautifulSoup, url: str) -> Optional[str]:
        """OGPç”»åƒã‚’å–å¾—"""
        og_image = soup.find('meta', property='og:image')
        if og_image and og_image.get('content'):
            image_url = self._normalize_image_url(og_image['content'], url)
            logger.info(f"ğŸ–¼ï¸ [PERPLEXITY] Found OGP image for {url}: {image_url}")
            return image_url
        logger.debug(f"ğŸ” [PERPLEXITY] No OGP image found for {url}")
        return None
    
    def _fetch_twitter_image(self, soup: BeautifulSoup, url: str) -> Optional[str]:
        """Twitter Cardç”»åƒã‚’å–å¾—"""
        twitter_image = soup.find('meta', attrs={'name': 'twitter:image'})
        if twitter_image and twitter_image.get('content'):
            image_url = self._normalize_image_url(twitter_image['content'], url)
            logger.debug(f"ğŸ–¼ï¸ [PERPLEXITY] Found Twitter image for {url}: {image_url}")
            return image_url
        return None
    
    def _fetch_kurashiru_image(self, soup: BeautifulSoup, url: str) -> Optional[str]:
        """ã‚¯ãƒ©ã‚·ãƒ«å°‚ç”¨ç”»åƒã‚’å–å¾—"""
        logger.debug(f"ğŸ” [PERPLEXITY] Searching for Kurashiru image in {url}")
        all_imgs = soup.find_all('img')
        logger.debug(f"ğŸ” [PERPLEXITY] Found {len(all_imgs)} img tags in Kurashiru page")
        
        img_tag = soup.find('img', class_=lambda x: x and ('recipe-image' in str(x).lower() or 'main-image' in str(x).lower() or 'hero-image' in str(x).lower()))
        if not img_tag:
            img_tag = soup.find('img', attrs={'data-src': True})
        if not img_tag:
            video_tag = soup.find('video')
            if video_tag and video_tag.get('poster'):
                image_url = self._normalize_image_url(video_tag['poster'], url)
                logger.info(f"ğŸ–¼ï¸ [PERPLEXITY] Found Kurashiru video poster for {url}: {image_url}")
                return image_url
        if img_tag:
            image_url = img_tag.get('src') or img_tag.get('data-src')
            if image_url:
                image_url = self._normalize_image_url(image_url, url)
                logger.info(f"ğŸ–¼ï¸ [PERPLEXITY] Found Kurashiru image for {url}: {image_url}")
                return image_url
        logger.debug(f"âš ï¸ [PERPLEXITY] No Kurashiru-specific image found for {url}")
        return None
    
    def _fetch_delishkitchen_image(self, soup: BeautifulSoup, url: str) -> Optional[str]:
        """ãƒ‡ãƒªãƒƒã‚·ãƒ¥ã‚­ãƒƒãƒãƒ³å°‚ç”¨ç”»åƒã‚’å–å¾—"""
        img_tag = soup.find('img', class_=lambda x: x and ('recipe-image' in str(x).lower() or 'main-image' in str(x).lower() or 'hero-image' in str(x).lower()))
        if not img_tag:
            img_tag = soup.find('img', attrs={'data-src': True})
        if img_tag:
            image_url = img_tag.get('src') or img_tag.get('data-src')
            if image_url:
                image_url = self._normalize_image_url(image_url, url)
                logger.debug(f"ğŸ–¼ï¸ [PERPLEXITY] Found DelishKitchen image for {url}: {image_url}")
                return image_url
        return None
    
    def _fetch_fallback_image(self, soup: BeautifulSoup, url: str) -> Optional[str]:
        """ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”»åƒã‚’å–å¾—ï¼ˆã‚¢ã‚¤ã‚³ãƒ³ã‚„ãƒ­ã‚´ã‚’é™¤å¤–ï¼‰"""
        img_tags = soup.find_all('img')
        skip_keywords = ['icon', 'logo', 'avatar', 'button', 'badge', 'spinner', 'loading']
        
        for img in img_tags:
            src = img.get('src') or img.get('data-src')
            if not src:
                continue
            
            # ã‚¢ã‚¤ã‚³ãƒ³ã‚„ãƒ­ã‚´ã‚’é™¤å¤–
            if any(skip in src.lower() for skip in skip_keywords):
                continue
            
            # ã‚µã‚¤ã‚ºãŒå¤§ããã†ãªç”»åƒã‚’å„ªå…ˆ
            width = img.get('width')
            height = img.get('height')
            if width and height:
                try:
                    w = int(str(width).replace('px', ''))
                    h = int(str(height).replace('px', ''))
                    if w < 100 or h < 100:
                        continue
                except ValueError:
                    pass
            
            image_url = self._normalize_image_url(src, url)
            logger.debug(f"ğŸ–¼ï¸ [PERPLEXITY] Found fallback image for {url}: {image_url}")
            return image_url
        
        return None
    
    async def _fetch_recipe_image(self, url: str) -> Optional[str]:
        """
        ãƒ¬ã‚·ãƒ”ãƒšãƒ¼ã‚¸ã‹ã‚‰ç”»åƒURLã‚’å–å¾—
        
        Args:
            url: ãƒ¬ã‚·ãƒ”ãƒšãƒ¼ã‚¸ã®URL
        
        Returns:
            ç”»åƒURLï¼ˆå–å¾—å¤±æ•—æ™‚ã¯Noneï¼‰
        """
        try:
            # HTMLã‚’å–å¾—
            response = requests.get(
                url, 
                timeout=5, 
                headers={
                    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
                }
            )
            response.raise_for_status()
            
            # BeautifulSoupã§ãƒ‘ãƒ¼ã‚¹
            soup = BeautifulSoup(response.text, 'lxml')
            
            # ãƒ‡ãƒãƒƒã‚°: HTMLã®ä¸€éƒ¨ã‚’ãƒ­ã‚°å‡ºåŠ›ï¼ˆæœ€åˆã®1000æ–‡å­—ï¼‰
            logger.debug(f"ğŸ” [PERPLEXITY] HTML preview for {url}: {response.text[:1000]}")
            
            # 1. OGPç”»åƒã‚’å„ªå…ˆçš„ã«å–å¾—
            image_url = self._fetch_ogp_image(soup, url)
            if image_url:
                return image_url
            
            # 2. Twitter Cardç”»åƒ
            image_url = self._fetch_twitter_image(soup, url)
            if image_url:
                return image_url
            
            # 3. ã‚¯ãƒ©ã‚·ãƒ«å°‚ç”¨ç”»åƒ
            if 'kurashiru.com' in url:
                image_url = self._fetch_kurashiru_image(soup, url)
                if image_url:
                    return image_url
            
            # 4. ãƒ‡ãƒªãƒƒã‚·ãƒ¥ã‚­ãƒƒãƒãƒ³å°‚ç”¨ç”»åƒ
            if 'delishkitchen.tv' in url:
                image_url = self._fetch_delishkitchen_image(soup, url)
                if image_url:
                    return image_url
            
            # 5. ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”»åƒ
            image_url = self._fetch_fallback_image(soup, url)
            if image_url:
                return image_url
            
            logger.warning(f"âš ï¸ [PERPLEXITY] No image found for {url}")
            return None
            
        except requests.exceptions.Timeout:
            logger.warning(f"âš ï¸ [PERPLEXITY] Timeout while fetching image from {url}")
            return None
        except requests.exceptions.RequestException as e:
            logger.warning(f"âš ï¸ [PERPLEXITY] Request error while fetching image from {url}: {e}")
            return None
        except Exception as e:
            logger.warning(f"âš ï¸ [PERPLEXITY] Failed to fetch image from {url}: {e}")
            return None

