#!/usr/bin/env python3
"""
WebSearchResultIntegrator - Webæ¤œç´¢çµæœçµ±åˆ

Webæ¤œç´¢çµæœã¨å€™è£œãƒªã‚¹ãƒˆã‚’çµ±åˆã™ã‚‹å‡¦ç†ã‚’æ‹…å½“
"""

from typing import Dict, Any, List, Optional
from config.loggers import GenericLogger


class WebSearchResultIntegrator:
    """Webæ¤œç´¢çµæœçµ±åˆãƒãƒ³ãƒ‰ãƒ©ãƒ¼"""
    
    def __init__(self):
        """åˆæœŸåŒ–"""
        self.logger = GenericLogger("service", "llm.response.web_integrator")
    
    def integrate(self, candidates: List[Dict[str, Any]], task_id: str, task4_data: Optional[Dict[str, Any]] = None, utils = None) -> List[Dict[str, Any]]:
        """
        Webæ¤œç´¢çµæœã‚’ä¸»èœææ¡ˆçµæœã«çµ±åˆ
        
        Args:
            candidates: ä¸»èœææ¡ˆã®å€™è£œãƒªã‚¹ãƒˆ
            task_id: ã‚¿ã‚¹ã‚¯ID
            task4_data: task4ã®å®Ÿè¡Œçµæœãƒ‡ãƒ¼ã‚¿
            utils: ResponseProcessorUtilsã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
        
        Returns:
            URLæƒ…å ±ãŒçµ±åˆã•ã‚ŒãŸå€™è£œãƒªã‚¹ãƒˆ
        """
        try:
            # task4ã®çµæœã‹ã‚‰Webæ¤œç´¢çµæœã‚’å–å¾—
            web_search_results = []
            if task4_data and task4_data.get("success") and task4_data.get("data"):
                web_data = task4_data["data"]
                # Webæ¤œç´¢çµæœã‹ã‚‰ãƒ¬ã‚·ãƒ”ãƒªã‚¹ãƒˆã‚’æŠ½å‡º
                # å˜ä¸€ã‚«ãƒ†ã‚´ãƒªææ¡ˆã®å ´åˆ: {"main_dish": {...}}, {"side_dish": {...}}, {"soup": {...}}
                # ä¸€æ‹¬ææ¡ˆã®å ´åˆ: {"llm_menu": {...}, "rag_menu": {...}}
                # ä¸»èœãƒ»å‰¯èœãƒ»æ±ç‰©ã®ã„ãšã‚Œã‹ãŒç›´æ¥å­˜åœ¨ã™ã‚‹å ´åˆï¼ˆå˜ä¸€ã‚«ãƒ†ã‚´ãƒªææ¡ˆï¼‰
                for category in ["main_dish", "side_dish", "soup"]:
                    if category in web_data and isinstance(web_data[category], dict) and "recipes" in web_data[category]:
                        recipes = web_data[category].get("recipes", [])
                        web_search_results = recipes
                        break
                # ä¸€æ‹¬ææ¡ˆã®å ´åˆï¼ˆå¾Œæ–¹äº’æ›æ€§ã®ãŸã‚ï¼‰
                if not web_search_results and "rag_menu" in web_data and "main_dish" in web_data["rag_menu"]:
                    recipes = web_data["rag_menu"]["main_dish"].get("recipes", [])
                    web_search_results = recipes
            
            if not web_search_results:
                self.logger.debug(f"ğŸ” [WebSearchResultIntegrator] No web search results found for task {task_id}")
                return candidates
            
            # ä½¿ç”¨æ¸ˆã¿ã®Webæ¤œç´¢çµæœã‚’è¨˜éŒ²ï¼ˆé‡è¤‡ã‚’é¿ã‘ã‚‹ãŸã‚ï¼‰
            used_web_results = set()
            
            # ã‚¿ã‚¤ãƒˆãƒ«ãƒãƒƒãƒãƒ³ã‚°ç”¨ã®ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°
            def normalize_title(title: str) -> str:
                """ã‚¿ã‚¤ãƒˆãƒ«ã‚’æ­£è¦åŒ–ï¼ˆæ¯”è¼ƒç”¨ï¼‰"""
                if not title:
                    return ""
                # ç©ºç™½ã‚’é™¤å»ã€å°æ–‡å­—ã«å¤‰æ›
                return title.strip().lower()
            
            def find_matching_web_result(candidate_title: str) -> Optional[Dict[str, Any]]:
                """å€™è£œã®ã‚¿ã‚¤ãƒˆãƒ«ã«ä¸€è‡´ã™ã‚‹Webæ¤œç´¢çµæœã‚’æ¢ã™"""
                normalized_candidate_title = normalize_title(candidate_title)
                
                # 1. å®Œå…¨ä¸€è‡´ã‚’æ¢ã™
                for idx, web_result in enumerate(web_search_results):
                    if idx in used_web_results:
                        continue
                    web_title = web_result.get("title", "")
                    if normalize_title(web_title) == normalized_candidate_title:
                        used_web_results.add(idx)
                        self.logger.debug(f"ğŸ”— [WebSearchResultIntegrator] Exact title match: '{candidate_title}' <-> '{web_title}'")
                        return web_result
                
                # 2. éƒ¨åˆ†ä¸€è‡´ã‚’æ¢ã™ï¼ˆå€™è£œã®ã‚¿ã‚¤ãƒˆãƒ«ãŒWebæ¤œç´¢çµæœã®ã‚¿ã‚¤ãƒˆãƒ«ã«å«ã¾ã‚Œã‚‹ã€ã¾ãŸã¯ãã®é€†ï¼‰
                for idx, web_result in enumerate(web_search_results):
                    if idx in used_web_results:
                        continue
                    web_title = web_result.get("title", "")
                    normalized_web_title = normalize_title(web_title)
                    
                    # å€™è£œã®ã‚¿ã‚¤ãƒˆãƒ«ãŒWebæ¤œç´¢çµæœã®ã‚¿ã‚¤ãƒˆãƒ«ã«å«ã¾ã‚Œã‚‹
                    if normalized_candidate_title in normalized_web_title:
                        used_web_results.add(idx)
                        self.logger.debug(f"ğŸ”— [WebSearchResultIntegrator] Partial match (candidate in web): '{candidate_title}' in '{web_title}'")
                        return web_result
                    
                    # Webæ¤œç´¢çµæœã®ã‚¿ã‚¤ãƒˆãƒ«ãŒå€™è£œã®ã‚¿ã‚¤ãƒˆãƒ«ã«å«ã¾ã‚Œã‚‹
                    if normalized_web_title in normalized_candidate_title:
                        used_web_results.add(idx)
                        self.logger.debug(f"ğŸ”— [WebSearchResultIntegrator] Partial match (web in candidate): '{web_title}' in '{candidate_title}'")
                        return web_result
                
                return None
            
            # å€™è£œã¨Webæ¤œç´¢çµæœã‚’çµ±åˆï¼ˆã‚¿ã‚¤ãƒˆãƒ«ãƒ™ãƒ¼ã‚¹ã®ãƒãƒƒãƒãƒ³ã‚°ï¼‰
            integrated_candidates = []
            for i, candidate in enumerate(candidates):
                integrated_candidate = candidate.copy()
                
                # sourceãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãŒå­˜åœ¨ã—ãªã„å ´åˆã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤"web"ã‚’è¨­å®š
                if "source" not in integrated_candidate:
                    integrated_candidate["source"] = "web"
                
                # ã‚¿ã‚¤ãƒˆãƒ«ãƒ™ãƒ¼ã‚¹ã§å¯¾å¿œã™ã‚‹Webæ¤œç´¢çµæœã‚’å–å¾—
                candidate_title = candidate.get("title", "")
                web_result = find_matching_web_result(candidate_title)
                
                if web_result and web_result.get("url"):
                    # URLæƒ…å ±ã‚’çµ±åˆï¼ˆsourceã¯æ—¢å­˜ã®å€¤ã‚’ä¿æŒï¼‰
                    domain = utils.extract_domain(web_result.get("url", "")) if utils else ""
                    url_info = {
                        "title": web_result.get("title", ""),
                        "url": web_result.get("url", ""),
                        "domain": domain
                    }
                    # ç”»åƒURLãŒå­˜åœ¨ã™ã‚‹å ´åˆã¯è¿½åŠ 
                    if web_result.get("image_url"):
                        url_info["image_url"] = web_result.get("image_url")
                        self.logger.debug(f"ğŸ–¼ï¸ [WebSearchResultIntegrator] Found image URL for candidate '{candidate_title}': {web_result.get('image_url')}")
                    integrated_candidate["urls"] = [url_info]
                    # URLãŒå­˜åœ¨ã™ã‚‹å ´åˆã§ã‚‚ã€å…ƒã®sourceï¼ˆllm/ragï¼‰ã‚’ä¿æŒ
                    # Webæ¤œç´¢ã¯ãƒ¬ã‚·ãƒ”è©³ç´°å–å¾—ã®ãŸã‚ã®è£œåŠ©æƒ…å ±ã§ã‚ã‚Šã€å‡ºå…¸ã¯å¤‰ãˆãªã„
                    self.logger.debug(f"ğŸ”— [WebSearchResultIntegrator] Integrated URLs for candidate '{candidate_title}': {integrated_candidate.get('urls', [])}, source: {integrated_candidate.get('source', 'N/A')}")
                elif web_result:
                    self.logger.warning(f"âš ï¸ [WebSearchResultIntegrator] Web search result matched for '{candidate_title}' but has no URL")
                else:
                    self.logger.debug(f"ğŸ” [WebSearchResultIntegrator] No matching web search result found for candidate '{candidate_title}'")
                
                integrated_candidates.append(integrated_candidate)
            
            self.logger.debug(f"âœ… [WebSearchResultIntegrator] Successfully integrated web search results for {len(integrated_candidates)} candidates")
            return integrated_candidates
            
        except Exception as e:
            self.logger.error(f"âŒ [WebSearchResultIntegrator] Error integrating web search results: {e}")
            return candidates

